{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part 1 For Beginners Bag Of Words](https://www.kaggle.com/c/word2vec-nlp-tutorial#part-1-for-beginners-bag-of-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "\n",
    "train = pandas.read_csv(\n",
    "    'labeledTrainData.tsv.gz',\n",
    "    compression='gzip',\n",
    "    header=0,\n",
    "    delimiter='\\t',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def clean_text(review: str) -> str:\n",
    "    review = BeautifulSoup(review, 'html5lib').get_text()\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of the loop, we use built-in `apply` method which applies a callable on each value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review'] = train['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds   by timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager  nicholas bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1   with all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1     the classic war of the worlds   by timothy ...\n",
       "2  \"7759_3\"          0   the film starts with a manager  nicholas bell...\n",
       "3  \"3630_4\"          0   it must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1   superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, instead of manual cleaning up stop-words, we pass `stop_words` straight to the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words=stop_words, max_features=5000)\n",
    "train_features = vectorizer.fit_transform(train['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `n_jobs=-1` sets the number of parallel jobs to the number of cores (by default it's just 1). It dramatically decreased training time for me.\n",
    "\n",
    "Also, I set `random_state` to get a reproducible result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ").fit(train_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv(\n",
    "    'testData.tsv.gz',\n",
    "    header=0,\n",
    "    compression='gzip',\n",
    "    delimiter='\\t',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")\n",
    "test['review'] = test['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vectorizer.transform(test['review'])\n",
    "sentiment = forest.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pandas.DataFrame({'id': test['id'], 'sentiment': sentiment})\n",
    "output.to_csv('part_1.csv', index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at which features (aka words) influence our predicted sentiment at most. Random forest instance has a nice attribute `feature_importances_` which stands for itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worst</td>\n",
       "      <td>0.020051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.018778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waste</td>\n",
       "      <td>0.011403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.010839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awful</td>\n",
       "      <td>0.009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>terrible</td>\n",
       "      <td>0.007697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boring</td>\n",
       "      <td>0.007548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.007332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>best</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nothing</td>\n",
       "      <td>0.005559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stupid</td>\n",
       "      <td>0.005515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>poor</td>\n",
       "      <td>0.005354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.005264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>worse</td>\n",
       "      <td>0.005183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>horrible</td>\n",
       "      <td>0.004745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0       worst    0.020051\n",
       "1         bad    0.018778\n",
       "2       waste    0.011403\n",
       "3       great    0.010839\n",
       "4       awful    0.009708\n",
       "5    terrible    0.007697\n",
       "6      boring    0.007548\n",
       "7   excellent    0.007332\n",
       "8        best    0.006787\n",
       "9     nothing    0.005559\n",
       "10     stupid    0.005515\n",
       "11       poor    0.005354\n",
       "12  wonderful    0.005264\n",
       "13      worse    0.005183\n",
       "14   horrible    0.004745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "pandas.DataFrame(\n",
    "    sorted(zip(vectorizer.get_feature_names(), forest.feature_importances_), key=itemgetter(1), reverse=True)[:15],\n",
    "    columns=['feature', 'importance'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense, hé?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part 2 Word Vectors](https://www.kaggle.com/c/word2vec-nlp-tutorial#part-2-word-vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train: pandas.DataFrame = pandas.read_csv(\n",
    "    'labeledTrainData.tsv.gz',\n",
    "    compression='gzip',\n",
    "    header=0,\n",
    "    delimiter='\\t',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")\n",
    "unlabeled_train: pandas.DataFrame = pandas.read_csv(\n",
    "    'unlabeledTrainData.tsv.gz',\n",
    "    compression='gzip',\n",
    "    header=0,\n",
    "    delimiter='\\t',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/eigenein/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nltk.data\n",
    "\n",
    "# Change the path if you wish.\n",
    "nltk_path = Path.home() / 'nltk_data'\n",
    "nltk_path.mkdir(exist_ok=True)\n",
    "nltk.download('punkt', download_dir=str(nltk_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3af9b15f03f4a5aafd3c8210fd7a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Cleaning…', max=75000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "reviews: List[str] = [*unlabeled_train['review'], *train['review']]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    sentences: List[List[str]] = [\n",
    "        clean_text(sentence).split()\n",
    "        for review in tqdm_notebook(reviews, desc='Cleaning…')\n",
    "        for sentence in tokenizer.tokenize(review)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s (%(name)s) [%(levelname)s] %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%d-%m %H:%M:%S',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-08 15:13:32 (summarizer.preprocessing.cleaner) [INFO] 'pattern' package not found; tag filters are not available for English\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] collecting all words and their counts\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #10000, processed 228386 words, keeping 17381 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #20000, processed 450696 words, keeping 24739 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #30000, processed 676534 words, keeping 29983 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #40000, processed 901155 words, keeping 34165 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #50000, processed 1122654 words, keeping 37737 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #60000, processed 1349724 words, keeping 41004 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #70000, processed 1576974 words, keeping 43944 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #80000, processed 1802672 words, keeping 46461 word types\n",
      "10-08 15:13:32 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #90000, processed 2020732 words, keeping 48717 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #100000, processed 2248354 words, keeping 50917 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #110000, processed 2474025 words, keeping 53078 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #120000, processed 2700945 words, keeping 55211 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #130000, processed 2927805 words, keeping 57005 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #140000, processed 3147960 words, keeping 58752 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #150000, processed 3370770 words, keeping 60459 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #160000, processed 3593433 words, keeping 62116 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #170000, processed 3822790 words, keeping 63728 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #180000, processed 4046892 words, keeping 65310 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #190000, processed 4275844 words, keeping 66903 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #200000, processed 4503021 words, keeping 68310 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #210000, processed 4733100 words, keeping 69728 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #220000, processed 4956134 words, keeping 71166 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #230000, processed 5177498 words, keeping 72414 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #240000, processed 5400376 words, keeping 73719 word types\n",
      "10-08 15:13:33 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #250000, processed 5626220 words, keeping 75007 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #260000, processed 5852165 words, keeping 76193 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #270000, processed 6075511 words, keeping 77378 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #280000, processed 6294196 words, keeping 78550 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #290000, processed 6521195 words, keeping 79729 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #300000, processed 6746461 words, keeping 80790 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #310000, processed 6973912 words, keeping 81916 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #320000, processed 7195140 words, keeping 82985 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #330000, processed 7419901 words, keeping 84034 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #340000, processed 7639713 words, keeping 85132 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #350000, processed 7866173 words, keeping 86154 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #360000, processed 8088732 words, keeping 87119 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #370000, processed 8312402 words, keeping 88113 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #380000, processed 8535370 words, keeping 89158 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #390000, processed 8758807 words, keeping 90136 word types\n",
      "10-08 15:13:34 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #400000, processed 8983630 words, keeping 91041 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #410000, processed 9210427 words, keeping 91989 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #420000, processed 9432102 words, keeping 92851 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #430000, processed 9656525 words, keeping 93810 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #440000, processed 9883380 words, keeping 94761 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #450000, processed 10111110 words, keeping 95598 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #460000, processed 10333019 words, keeping 96460 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #470000, processed 10554441 words, keeping 97301 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #480000, processed 10777044 words, keeping 98114 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #490000, processed 10996991 words, keeping 98941 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #500000, processed 11218460 words, keeping 99780 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #510000, processed 11447595 words, keeping 100695 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #520000, processed 11675398 words, keeping 101496 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #530000, processed 11899492 words, keeping 102396 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #540000, processed 12125950 words, keeping 103425 word types\n",
      "10-08 15:13:35 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #550000, processed 12351093 words, keeping 104514 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #560000, processed 12570787 words, keeping 105565 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #570000, processed 12799191 words, keeping 106573 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #580000, processed 13017708 words, keeping 107495 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #590000, processed 13237718 words, keeping 108363 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #600000, processed 13461680 words, keeping 109233 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #610000, processed 13681862 words, keeping 110025 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #620000, processed 13904672 words, keeping 110921 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #630000, processed 14126362 words, keeping 111683 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #640000, processed 14346469 words, keeping 112448 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #650000, processed 14569962 words, keeping 113311 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #660000, processed 14787210 words, keeping 114008 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #670000, processed 15008818 words, keeping 114731 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #680000, processed 15232354 words, keeping 115531 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #690000, processed 15455464 words, keeping 116273 word types\n",
      "10-08 15:13:36 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #700000, processed 15677326 words, keeping 116935 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #710000, processed 15898730 words, keeping 117641 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #720000, processed 16124894 words, keeping 118306 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #730000, processed 16348486 words, keeping 118950 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #740000, processed 16572058 words, keeping 119707 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #750000, processed 16796402 words, keeping 120413 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #760000, processed 17018535 words, keeping 121087 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #770000, processed 17243121 words, keeping 121743 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #780000, processed 17456218 words, keeping 122444 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] PROGRESS: at sentence #790000, processed 17678724 words, keeping 123131 word types\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] collected 123504 word types from a corpus of 17798270 raw words and 795538 sentences\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] Loading a fresh vocabulary\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] effective_min_count=40 retains 16490 unique words (13% of original 123504, drops 107014)\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] effective_min_count=40 leaves 17239125 word corpus (96% of original 17798270, drops 559145)\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] deleting the raw counts dictionary of 123504 items\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] sample=0.001 downsamples 48 most-common words\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] downsampling leaves estimated 12749798 word corpus (74.0% of prior 17239125)\n",
      "10-08 15:13:37 (gensim.models.base_any2vec) [INFO] estimated required memory for 16490 words and 300 dimensions: 47821000 bytes\n",
      "10-08 15:13:37 (gensim.models.word2vec) [INFO] resetting layer weights\n",
      "10-08 15:13:38 (gensim.models.base_any2vec) [INFO] training model with 8 workers on 16490 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "10-08 15:13:39 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 6.57% examples, 831528 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:13:40 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 13.22% examples, 837577 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:13:41 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 19.82% examples, 837848 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:13:42 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 26.22% examples, 834725 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:13:43 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 32.51% examples, 825654 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:44 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 38.87% examples, 823621 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:45 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 45.28% examples, 821894 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:13:46 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 51.39% examples, 816252 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:47 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 57.48% examples, 812096 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:13:48 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 63.73% examples, 809360 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:49 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 69.92% examples, 807707 words/s, in_qsize 16, out_qsize 1\n",
      "10-08 15:13:50 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 76.25% examples, 804812 words/s, in_qsize 15, out_qsize 1\n",
      "10-08 15:13:51 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 82.40% examples, 802343 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:52 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 88.53% examples, 799848 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:13:53 (gensim.models.base_any2vec) [INFO] EPOCH 1 - PROGRESS: at 94.48% examples, 796751 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 7 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 6 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 5 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 4 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 3 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "10-08 15:13:54 (gensim.models.base_any2vec) [INFO] EPOCH - 1 : training on 17798270 raw words (12750360 effective words) took 16.0s, 795146 effective words/s\n",
      "10-08 15:13:55 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 5.86% examples, 743693 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:56 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 12.01% examples, 755683 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:57 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 18.08% examples, 760141 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:13:58 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 24.29% examples, 766892 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:13:59 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 30.33% examples, 767085 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:00 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 36.37% examples, 767724 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:14:01 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 42.32% examples, 761871 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:02 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 48.31% examples, 762133 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:03 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 54.13% examples, 759781 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:04 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 60.06% examples, 758341 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:05 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 65.99% examples, 757337 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:06 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 71.87% examples, 756618 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:07 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 77.93% examples, 756836 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:08 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 84.08% examples, 757087 words/s, in_qsize 12, out_qsize 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-08 15:14:09 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 89.88% examples, 755619 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:10 (gensim.models.base_any2vec) [INFO] EPOCH 2 - PROGRESS: at 95.59% examples, 753131 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 7 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 6 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 5 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 4 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 3 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "10-08 15:14:11 (gensim.models.base_any2vec) [INFO] EPOCH - 2 : training on 17798270 raw words (12748608 effective words) took 16.9s, 753591 effective words/s\n",
      "10-08 15:14:12 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 5.93% examples, 745802 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:13 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 11.96% examples, 749267 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:14 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 17.63% examples, 740803 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:15 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 23.76% examples, 749762 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:14:16 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 30.33% examples, 766397 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:17 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 35.91% examples, 756566 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:18 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 41.41% examples, 747867 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:19 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 46.69% examples, 736453 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:20 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 53.14% examples, 744710 words/s, in_qsize 16, out_qsize 1\n",
      "10-08 15:14:21 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 59.56% examples, 752205 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:22 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 66.72% examples, 766364 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:23 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 74.27% examples, 781099 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:24 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 81.62% examples, 792102 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:25 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 88.82% examples, 799273 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] EPOCH 3 - PROGRESS: at 95.97% examples, 806352 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 7 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 6 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 5 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 4 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 3 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "10-08 15:14:26 (gensim.models.base_any2vec) [INFO] EPOCH - 3 : training on 17798270 raw words (12748292 effective words) took 15.7s, 813687 effective words/s\n",
      "10-08 15:14:27 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 7.36% examples, 921295 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:28 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 14.28% examples, 895734 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:29 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 20.98% examples, 879594 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:30 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 28.36% examples, 895380 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:31 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 35.16% examples, 889341 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:32 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 41.18% examples, 868999 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:33 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 47.54% examples, 855643 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:34 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 53.97% examples, 850911 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:35 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 60.12% examples, 842993 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:36 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 66.44% examples, 838191 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:37 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 72.68% examples, 833363 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:38 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 78.89% examples, 829520 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:39 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 85.02% examples, 825079 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:40 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 91.16% examples, 821364 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:41 (gensim.models.base_any2vec) [INFO] EPOCH 4 - PROGRESS: at 97.24% examples, 817690 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 7 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 6 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 5 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 4 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 3 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "10-08 15:14:42 (gensim.models.base_any2vec) [INFO] EPOCH - 4 : training on 17798270 raw words (12749118 effective words) took 15.6s, 817042 effective words/s\n",
      "10-08 15:14:43 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 5.86% examples, 727704 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:44 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 11.95% examples, 752536 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:45 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 17.74% examples, 744888 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:46 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 23.43% examples, 737179 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:47 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 29.38% examples, 740668 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:48 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 35.42% examples, 744935 words/s, in_qsize 16, out_qsize 1\n",
      "10-08 15:14:49 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 41.29% examples, 744760 words/s, in_qsize 13, out_qsize 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-08 15:14:50 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 47.36% examples, 746547 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:51 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 53.08% examples, 744268 words/s, in_qsize 16, out_qsize 1\n",
      "10-08 15:14:52 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 58.94% examples, 743564 words/s, in_qsize 16, out_qsize 0\n",
      "10-08 15:14:53 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 65.05% examples, 746386 words/s, in_qsize 13, out_qsize 2\n",
      "10-08 15:14:54 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 71.31% examples, 750560 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:55 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 77.47% examples, 752652 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:56 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 83.78% examples, 755235 words/s, in_qsize 14, out_qsize 1\n",
      "10-08 15:14:57 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 90.31% examples, 759704 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:58 (gensim.models.base_any2vec) [INFO] EPOCH 5 - PROGRESS: at 96.43% examples, 760087 words/s, in_qsize 15, out_qsize 0\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 7 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 6 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 5 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 4 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 3 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 2 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 1 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] worker thread finished; awaiting finish of 0 more threads\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] EPOCH - 5 : training on 17798270 raw words (12749371 effective words) took 16.8s, 758832 effective words/s\n",
      "10-08 15:14:59 (gensim.models.base_any2vec) [INFO] training on a 88991350 raw words (63745749 effective words) took 81.1s, 786033 effective words/s\n",
      "10-08 15:14:59 (gensim.models.keyedvectors) [INFO] precomputing L2-norms of word weight vectors\n",
      "10-08 15:14:59 (gensim.utils) [INFO] saving Word2Vec object under 300features_40minwords_10context.model.gz, separately None\n",
      "10-08 15:14:59 (gensim.utils) [INFO] not storing attribute vectors_norm\n",
      "10-08 15:14:59 (gensim.utils) [INFO] not storing attribute cum_table\n",
      "10-08 15:15:08 (gensim.utils) [INFO] saved 300features_40minwords_10context.model.gz\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences, workers=cpu_count(), size=300, min_count=40, window=10, sample=1e-3)\n",
    "\n",
    "# If you don't plan to train the model any further,\n",
    "# calling `init_sims` will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "model.save('300features_40minwords_10context.model.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra word: kitchen\n",
      "Similar: [('queen', 0.5384258031845093), ('princess', 0.5378516316413879), ('prince', 0.49575579166412354)]\n",
      "Similarity: 0.8874878\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    print('Extra word:', model.doesnt_match('man woman child kitchen'.split()))\n",
    "    print('Similar:', model.most_similar(positive='woman king'.split(), negative='man'.split(), topn=3))\n",
    "    print('Similarity:', model.similarity('darth', 'vader'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part 3 More Fun With Word Vectors](https://www.kaggle.com/c/word2vec-nlp-tutorial#part-3-more-fun-with-word-vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part 4 Comparing Deep And Non Deep Learning Methods](https://www.kaggle.com/c/word2vec-nlp-tutorial#part-4-comparing-deep-and-non-deep-learning-methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
