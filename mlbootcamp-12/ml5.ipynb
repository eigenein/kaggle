{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import hyperopt\n",
    "import itertools\n",
    "import math\n",
    "import numpy\n",
    "import operator\n",
    "import pandas\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    ensemble,\n",
    "    linear_model,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    naive_bayes,\n",
    "    neighbors,\n",
    "    neural_network,\n",
    "    svm,\n",
    ")\n",
    "import time\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = {'smoke': float, 'alco': float, 'active': float}\n",
    "\n",
    "def fix_ap(value):\n",
    "    value = abs(value)\n",
    "    while value > 500.0:\n",
    "        value /= 10.0\n",
    "    return value\n",
    "\n",
    "def read_csv(filename):\n",
    "    frame = pandas.read_csv(filename, sep=';', header=0, na_values='None', dtype=dtype).drop(['id'], axis=1)\n",
    "    \n",
    "    frame = pandas.get_dummies(frame, columns=[\n",
    "        # 'smoke',\n",
    "        # 'active',\n",
    "        # 'alco',\n",
    "        # 'gender',\n",
    "        # 'cholesterol',\n",
    "        # 'gluc',\n",
    "    ])\n",
    "    frame = frame.assign(\n",
    "        bmi=(frame['weight'] / frame['height'] ** 2),\n",
    "        # aged_smoke_0=(frame['smoke_0.0'] * frame['age']),\n",
    "        # aged_smoke_1=(frame['smoke_1.0'] * frame['age']),\n",
    "        # aged_active_0=(frame['active_0.0'] * frame['age']),\n",
    "        # aged_active_1=(frame['active_1.0'] * frame['age']),\n",
    "        # aged_alco_0=(frame['alco_0.0'] * frame['age']),\n",
    "        # aged_alco_1=(frame['alco_1.0'] * frame['age']),\n",
    "        # smoke_1_active_0=(frame['smoke_1.0'] * frame['active_0.0']),\n",
    "    )\n",
    "    \n",
    "    frame['ap_hi'] = frame['ap_hi'].apply(fix_ap)\n",
    "    frame['ap_lo'] = frame['ap_lo'].apply(fix_ap)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (70000, 12)\n",
      "y: (70000,)\n"
     ]
    }
   ],
   "source": [
    "train = read_csv('train.csv')\n",
    "\n",
    "X = train.drop('cardio', axis=1).values\n",
    "y = train['cardio'].values\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Param = collections.namedtuple('Param', 'min max step')\n",
    "\n",
    "def optimize_estimator(estimator, X, y, n_iter=10, scoring=None, refit=True, cv=None, **params):\n",
    "    def evaluate():\n",
    "        return model_selection.cross_val_score(estimator, X, y, scoring=scoring, cv=cv()).mean()\n",
    "    \n",
    "    def set_evaluate(key, value):\n",
    "        setattr(estimator, key, value)\n",
    "        return evaluate()\n",
    "    \n",
    "    params = list(params.items())\n",
    "    \n",
    "    print(f'Evaluating current model…')\n",
    "    current_score = evaluate()\n",
    "    print(f'Initial score: {current_score}')\n",
    "    print()\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        start_time = time.time()\n",
    "        early_stop = True\n",
    "        \n",
    "        # Shuffle params to lessen overfitting.\n",
    "        random.shuffle(params)\n",
    "        \n",
    "        # Tune each parameter.\n",
    "        for key, param in params:\n",
    "            current_value = getattr(estimator, key)\n",
    "            \n",
    "            # Choose the best value.\n",
    "            values = [current_value - param.step, current_value + param.step]\n",
    "            scores = [(value, set_evaluate(key, value)) for value in values if param.min <= value <= param.max]\n",
    "            best_value, best_score = max(scores, key=operator.itemgetter(1))\n",
    "            if best_score > current_score:\n",
    "                current_value = best_value\n",
    "                current_score = best_score\n",
    "                early_stop = False\n",
    "                print(f'[Iteration {i}] {key} = {current_value}. Score: {current_score}')\n",
    "                \n",
    "            # Restore current value.\n",
    "            setattr(estimator, key, current_value)\n",
    "        \n",
    "        print(f'[Iteration {i}] Finished in {(time.time() - start_time) / 60.0:.0f} min')\n",
    "        \n",
    "        if early_stop:\n",
    "            print(f'[Iteration {i}] No changes, stopping')\n",
    "            break\n",
    "            \n",
    "    print(f'Final score: {current_score}')\n",
    "\n",
    "    # Fit on the entire dataset if needed.\n",
    "    if refit:\n",
    "        estimator.fit(X, y)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `smoke`, `alco` and `active`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_helper = train.drop(['smoke', 'alco', 'active', 'cardio'], axis=1).values\n",
    "\n",
    "y_smoke = train['smoke'].values\n",
    "y_alco = train['alco'].values\n",
    "y_active = train['active'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoke_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.23903379653624574\n",
      "\n",
      "[Iteration 0] max_depth = 2. Score: -0.23894694753199386\n",
      "[Iteration 0] n_estimators = 101. Score: -0.2389436985974828\n",
      "[Iteration 0] subsample = 0.99. Score: -0.23891878010021855\n",
      "[Iteration 0] learning_rate = 0.11. Score: -0.23888698481217663\n",
      "[Iteration 0] reg_lambda = 0.99. Score: -0.2388868011920695\n",
      "[Iteration 0] scale_pos_weight = 0.99. Score: -0.23888182920125828\n",
      "[Iteration 0] 131s\n",
      "[Iteration 1] base_score = 0.51. Score: -0.238876029031722\n",
      "[Iteration 1] n_estimators = 100. Score: -0.23887548397229796\n",
      "[Iteration 1] learning_rate = 0.12. Score: -0.23882412756168442\n",
      "[Iteration 1] subsample = 1.0. Score: -0.23880976059404105\n",
      "[Iteration 1] 143s\n",
      "[Iteration 2] base_score = 0.52. Score: -0.23879865316904453\n",
      "[Iteration 2] reg_lambda = 1.0. Score: -0.23879560952809892\n",
      "[Iteration 2] learning_rate = 0.13. Score: -0.2387859703231932\n",
      "[Iteration 2] n_estimators = 99. Score: -0.23877473643329777\n",
      "[Iteration 2] 127s\n",
      "[Iteration 3] reg_lambda = 0.99. Score: -0.23877396390770983\n",
      "[Iteration 3] n_estimators = 100. Score: -0.23877346981261632\n",
      "[Iteration 3] 119s\n",
      "[Iteration 4] 127s\n",
      "[Iteration 4] No changes\n",
      "Final score: -0.23877346981261632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.52, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.13, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=0.99,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    smoke_estimator, X_helper, y_smoke, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "alco_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.19240139584600163\n",
      "\n",
      "[Iteration 0] subsample = 0.99. Score: -0.19237007084120925\n",
      "[Iteration 0] scale_pos_weight = 0.99. Score: -0.19233316932729289\n",
      "[Iteration 0] n_estimators = 101. Score: -0.19232625926163077\n",
      "[Iteration 0] 167s\n",
      "[Iteration 1] reg_alpha = 0.01. Score: -0.19227622539807737\n",
      "[Iteration 1] 194s\n",
      "[Iteration 2] 206s\n",
      "[Iteration 2] No changes\n",
      "Final score: -0.19227622539807737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=101, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=0.99)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    alco_estimator, X_helper, y_alco, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.49276407584835874\n",
      "\n",
      "[Iteration 0] gamma = 0.01. Score: -0.4927636724052\n",
      "[Iteration 0] reg_alpha = 0.01. Score: -0.49273419589277323\n",
      "[Iteration 0] max_depth = 4. Score: -0.49257788731186924\n",
      "[Iteration 0] learning_rate = 0.11. Score: -0.4924410642774138\n",
      "[Iteration 0] 170s\n",
      "[Iteration 1] gamma = 0.0. Score: -0.49243671928081795\n",
      "[Iteration 1] n_estimators = 99. Score: -0.4924262166722723\n",
      "[Iteration 1] 226s\n",
      "[Iteration 2] 211s\n",
      "[Iteration 2] No changes\n",
      "Final score: -0.4924262166722723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.11, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=99, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    active_estimator, X_helper, y_active, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `cardio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_importances(estimator):\n",
    "    for name, importance in sorted(zip(test, estimator.feature_importances_), key=operator.itemgetter(1), reverse=True):\n",
    "        print(f'{name}: {importance:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cardio_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.5394364373333194\n",
      "\n",
      "[Iteration 0] learning_rate = 0.11. Score: -0.5393749453345829\n",
      "[Iteration 0] scale_pos_weight = 0.99. Score: -0.5392783467426565\n",
      "[Iteration 0] n_estimators = 101. Score: -0.5392672082177659\n",
      "[Iteration 0] max_depth = 4. Score: -0.538863384332475\n",
      "[Iteration 0] colsample_bytree = 0.99. Score: -0.5388163985044684\n",
      "[Iteration 0] 182s\n",
      "[Iteration 1] n_estimators = 102. Score: -0.5388151821486524\n",
      "[Iteration 1] base_score = 0.49. Score: -0.5386688234785836\n",
      "[Iteration 1] subsample = 0.99. Score: -0.5386265987030663\n",
      "[Iteration 1] max_depth = 5. Score: -0.5385698473692777\n",
      "[Iteration 1] 265s\n",
      "[Iteration 2] n_estimators = 103. Score: -0.5385636610469058\n",
      "[Iteration 2] gamma = 0.01. Score: -0.5385547054296286\n",
      "[Iteration 2] 361s\n",
      "[Iteration 3] n_estimators = 102. Score: -0.5385461361413276\n",
      "[Iteration 3] 394s\n",
      "[Iteration 4] n_estimators = 101. Score: -0.5385324360616334\n",
      "[Iteration 4] 392s\n",
      "[Iteration 5] 380s\n",
      "[Iteration 5] No changes\n",
      "Final score: -0.5385324360616334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.49, colsample_bylevel=1, colsample_bytree=0.99,\n",
       "       gamma=0.01, learning_rate=0.11, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=101, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=0.99)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    cardio_estimator, X, y, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.2739567\n",
      "bmi: 0.1827666\n",
      "ap_hi: 0.1155332\n",
      "height: 0.0981453\n",
      "weight: 0.0962133\n",
      "ap_lo: 0.0699382\n",
      "cholesterol: 0.0552550\n",
      "gluc: 0.0401855\n",
      "active: 0.0224111\n",
      "gender: 0.0162287\n",
      "smoke: 0.0158424\n",
      "alco: 0.0135240\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv')\n",
    "X_helper_test = test.drop(['smoke', 'alco', 'active'], axis=1).values\n",
    "\n",
    "test['smoke'].fillna(pandas.Series(smoke_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['alco'].fillna(pandas.Series(alco_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['active'].fillna(pandas.Series(active_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "\n",
    "numpy.savetxt(f'xgboost.txt', cardio_estimator.predict_proba(test.values)[:, 1], fmt='%f')\n",
    "\n",
    "print_importances(cardio_estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
