{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import hyperopt\n",
    "import itertools\n",
    "import math\n",
    "import numpy\n",
    "import operator\n",
    "import pandas\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    ensemble,\n",
    "    linear_model,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    naive_bayes,\n",
    "    neighbors,\n",
    "    neural_network,\n",
    "    svm,\n",
    ")\n",
    "import time\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = {'smoke': float, 'alco': float, 'active': float, 'ap_hi': float, 'ap_lo': float}\n",
    "\n",
    "def fix_ap(value):\n",
    "    value = abs(value)\n",
    "    while value > 500.0:\n",
    "        value /= 10.0\n",
    "    return value\n",
    "\n",
    "def read_csv(filename):\n",
    "    frame = pandas.read_csv(filename, sep=';', header=0, na_values='None', dtype=dtype).drop(['id'], axis=1)\n",
    "    \n",
    "    frame = pandas.get_dummies(frame, columns=[\n",
    "        # 'smoke',\n",
    "        # 'active',\n",
    "        # 'alco',\n",
    "        # 'gender',\n",
    "        # 'cholesterol',\n",
    "        # 'gluc',\n",
    "    ])\n",
    "    frame = frame.assign(\n",
    "        bmi=(frame['weight'] / frame['height'] ** 2),\n",
    "        # aged_smoke_0=(frame['smoke_0.0'] * frame['age']),\n",
    "        # aged_smoke_1=(frame['smoke_1.0'] * frame['age']),\n",
    "        # aged_active_0=(frame['active_0.0'] * frame['age']),\n",
    "        # aged_active_1=(frame['active_1.0'] * frame['age']),\n",
    "        # aged_alco_0=(frame['alco_0.0'] * frame['age']),\n",
    "        # aged_alco_1=(frame['alco_1.0'] * frame['age']),\n",
    "        # smoke_1_active_0=(frame['smoke_1.0'] * frame['active_0.0']),\n",
    "    )\n",
    "    \n",
    "    # Fix negative and too large values.\n",
    "    frame['ap_hi'] = frame['ap_hi'].apply(fix_ap)\n",
    "    frame['ap_lo'] = frame['ap_lo'].apply(fix_ap)\n",
    "    \n",
    "    # Re-order ap_hi and ap_lo.\n",
    "    frame[['ap_hi', 'ap_lo']] = frame[['ap_hi', 'ap_lo']].apply(\n",
    "        lambda row: [row['ap_hi'], row['ap_lo']] if row['ap_hi'] > row['ap_lo'] else [row['ap_lo'], row['ap_hi']],\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (70000, 12)\n",
      "y: (70000,)\n"
     ]
    }
   ],
   "source": [
    "train = read_csv('train.csv')\n",
    "\n",
    "X = train.drop('cardio', axis=1).values\n",
    "y = train['cardio'].values\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Param = collections.namedtuple('Param', 'min max step')\n",
    "\n",
    "def optimize_estimator(estimator, X, y, n_iter=10, scoring=None, refit=True, cv=None, **params):\n",
    "    def evaluate():\n",
    "        return model_selection.cross_val_score(estimator, X, y, scoring=scoring, cv=cv()).mean()\n",
    "    \n",
    "    def set_evaluate(key, value):\n",
    "        setattr(estimator, key, value)\n",
    "        return evaluate()\n",
    "    \n",
    "    params = list(params.items())\n",
    "    \n",
    "    print(f'Evaluating current model…')\n",
    "    current_score = evaluate()\n",
    "    print(f'Initial score: {current_score}')\n",
    "    print()\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        start_time = time.time()\n",
    "        early_stop = True\n",
    "        \n",
    "        # Shuffle params to lessen overfitting.\n",
    "        random.shuffle(params)\n",
    "        \n",
    "        # Tune each parameter.\n",
    "        for key, param in params:\n",
    "            current_value = getattr(estimator, key)\n",
    "            \n",
    "            # Choose the best value.\n",
    "            values = [current_value - param.step, current_value + param.step]\n",
    "            scores = [(value, set_evaluate(key, value)) for value in values if param.min <= value <= param.max]\n",
    "            best_value, best_score = max(scores, key=operator.itemgetter(1))\n",
    "            if best_score > current_score:\n",
    "                current_value = best_value\n",
    "                current_score = best_score\n",
    "                early_stop = False\n",
    "                print(f'[Iteration {i}] {key} = {current_value}. Score: {current_score}')\n",
    "                \n",
    "            # Restore current value.\n",
    "            setattr(estimator, key, current_value)\n",
    "        \n",
    "        print(f'[Iteration {i}] Finished in {(time.time() - start_time) / 60.0:.0f} min')\n",
    "        \n",
    "        if early_stop:\n",
    "            print(f'[Iteration {i}] No changes, stopping')\n",
    "            break\n",
    "            \n",
    "    print(f'Final score: {current_score}')\n",
    "\n",
    "    # Fit on the entire dataset if needed.\n",
    "    if refit:\n",
    "        print(f'Final fitting…')\n",
    "        estimator.fit(X, y)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `smoke`, `alco` and `active`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_helper = train.drop(['smoke', 'alco', 'active', 'cardio'], axis=1).values\n",
    "\n",
    "y_smoke = train['smoke'].values\n",
    "y_alco = train['alco'].values\n",
    "y_active = train['active'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoke_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.23877346981261632\n",
      "\n",
      "[Iteration 0] 128s\n",
      "[Iteration 0] No changes\n",
      "Final score: -0.23877346981261632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.52, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.13, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=0.99,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    smoke_estimator, X_helper, y_smoke, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "alco_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.19227622539807737\n",
      "\n",
      "[Iteration 0] 206s\n",
      "[Iteration 0] No changes\n",
      "Final score: -0.19227622539807737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=101, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=0.99)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    alco_estimator, X_helper, y_alco, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.4924262166722723\n",
      "\n",
      "[Iteration 0] 213s\n",
      "[Iteration 0] No changes\n",
      "Final score: -0.4924262166722723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.11, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=99, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    active_estimator, X_helper, y_active, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `cardio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_importances(estimator):\n",
    "    for name, importance in sorted(zip(test, estimator.feature_importances_), key=operator.itemgetter(1), reverse=True):\n",
    "        print(f'{name}: {importance:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cardio_estimator = xgboost.XGBClassifier(nthread=2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model…\n",
      "Initial score: -0.5389153323250567\n",
      "\n",
      "[Iteration 0] base_score = 0.5. Score: -0.5388995685088614\n",
      "[Iteration 0] max_depth = 4. Score: -0.5387134496618897\n",
      "[Iteration 0] gamma = 0.02. Score: -0.5387117586461065\n",
      "[Iteration 0] reg_lambda = 0.99. Score: -0.5387098526465285\n",
      "[Iteration 0] 326s\n",
      "[Iteration 1] subsample = 0.98. Score: -0.5387072903563016\n",
      "[Iteration 1] 322s\n",
      "[Iteration 2] n_estimators = 100. Score: -0.5387029863095291\n",
      "[Iteration 2] 324s\n",
      "[Iteration 3] learning_rate = 0.1. Score: -0.5386959078842235\n",
      "[Iteration 3] base_score = 0.51. Score: -0.5386556783886562\n",
      "[Iteration 3] n_estimators = 99. Score: -0.5386424968896206\n",
      "[Iteration 3] 320s\n",
      "[Iteration 4] gamma = 0.03. Score: -0.5386423372311822\n",
      "[Iteration 4] 317s\n",
      "[Iteration 5] gamma = 0.04. Score: -0.5386348975915766\n",
      "[Iteration 5] 318s\n",
      "[Iteration 6] gamma = 0.05. Score: -0.5386347945247948\n",
      "[Iteration 6] 318s\n",
      "[Iteration 7] 319s\n",
      "[Iteration 7] No changes\n",
      "Final score: -0.5386347945247948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.51, colsample_bylevel=1, colsample_bytree=0.99,\n",
       "       gamma=0.05, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=99, nthread=2,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=0.99,\n",
       "       scale_pos_weight=0.99, seed=0, silent=True, subsample=0.98)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    cardio_estimator, X, y, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.2697183\n",
      "bmi: 0.1478873\n",
      "ap_hi: 0.1330986\n",
      "ap_lo: 0.0929577\n",
      "weight: 0.0809859\n",
      "height: 0.0795775\n",
      "cholesterol: 0.0760563\n",
      "gluc: 0.0514085\n",
      "active: 0.0253521\n",
      "smoke: 0.0169014\n",
      "alco: 0.0133803\n",
      "gender: 0.0126761\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv')\n",
    "X_helper_test = test.drop(['smoke', 'alco', 'active'], axis=1).values\n",
    "\n",
    "test['smoke'].fillna(pandas.Series(smoke_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['alco'].fillna(pandas.Series(alco_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['active'].fillna(pandas.Series(active_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "\n",
    "numpy.savetxt(f'xgboost.txt', cardio_estimator.predict_proba(test.values)[:, 1], fmt='%f')\n",
    "\n",
    "print_importances(cardio_estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
