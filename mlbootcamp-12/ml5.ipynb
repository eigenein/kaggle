{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import hyperopt\n",
    "import itertools\n",
    "import math\n",
    "import numpy\n",
    "import operator\n",
    "import pandas\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn import (\n",
    "    calibration,\n",
    "    ensemble,\n",
    "    linear_model,\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    naive_bayes,\n",
    "    neighbors,\n",
    "    neural_network,\n",
    "    svm,\n",
    ")\n",
    "import time\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = {'smoke': float, 'alco': float, 'active': float}\n",
    "\n",
    "def fix_ap(value):\n",
    "    value = abs(value)\n",
    "    while value > 500.0:\n",
    "        value /= 10.0\n",
    "    return value\n",
    "\n",
    "def read_csv(filename):\n",
    "    frame = pandas.read_csv(filename, sep=';', header=0, na_values='None', dtype=dtype).drop(['id'], axis=1)\n",
    "    \n",
    "    frame = pandas.get_dummies(frame, columns=[\n",
    "        # 'smoke',\n",
    "        # 'active',\n",
    "        # 'alco',\n",
    "        # 'gender',\n",
    "        # 'cholesterol',\n",
    "        # 'gluc',\n",
    "    ])\n",
    "    frame = frame.assign(\n",
    "        bmi=(frame['weight'] / frame['height'] ** 2),\n",
    "        # aged_smoke_0=(frame['smoke_0.0'] * frame['age']),\n",
    "        # aged_smoke_1=(frame['smoke_1.0'] * frame['age']),\n",
    "        # aged_active_0=(frame['active_0.0'] * frame['age']),\n",
    "        # aged_active_1=(frame['active_1.0'] * frame['age']),\n",
    "        # aged_alco_0=(frame['alco_0.0'] * frame['age']),\n",
    "        # aged_alco_1=(frame['alco_1.0'] * frame['age']),\n",
    "        # smoke_1_active_0=(frame['smoke_1.0'] * frame['active_0.0']),\n",
    "    )\n",
    "    \n",
    "    frame['ap_hi'] = frame['ap_hi'].apply(fix_ap)\n",
    "    frame['ap_lo'] = frame['ap_lo'].apply(fix_ap)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (70000, 12)\n",
      "y: (70000,)\n"
     ]
    }
   ],
   "source": [
    "train = read_csv('train.csv')\n",
    "\n",
    "X = train.drop('cardio', axis=1).values\n",
    "y = train['cardio'].values\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Param = collections.namedtuple('Param', 'min max step')\n",
    "\n",
    "def optimize_estimator(estimator, X, y, n_iter=10, scoring=None, refit=True, cv=None, **params):\n",
    "    def evaluate():\n",
    "        return model_selection.cross_val_score(estimator, X, y, scoring=scoring, cv=cv()).mean()\n",
    "    \n",
    "    def set_evaluate(key, value):\n",
    "        setattr(estimator, key, value)\n",
    "        return evaluate()\n",
    "    \n",
    "    params = list(params.items())\n",
    "    \n",
    "    print(f'Evaluating current model')\n",
    "    current_score = evaluate()\n",
    "    print(f'Initial score: {current_score}')\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        print()\n",
    "        print(f'Starting iteration {i}. Current score: {current_score}')\n",
    "        early_stop = True\n",
    "        \n",
    "        # Shuffle params to lessen overfitting.\n",
    "        random.shuffle(params)\n",
    "        \n",
    "        # Tune each parameter.\n",
    "        for key, param in params:\n",
    "            current_value = getattr(estimator, key)\n",
    "            print(f'[{key}] Current value: {current_value}')\n",
    "            \n",
    "            # Find out the optimal step.\n",
    "            best_step, best_value, best_score = max([\n",
    "                (step, current_value + step, set_evaluate(key, current_value + step))\n",
    "                for step in (-param.step, +param.step)\n",
    "                if param.min <= current_value + step <= param.max\n",
    "            ], default=(None, None, None), key=operator.itemgetter(1))\n",
    "            \n",
    "            # Check if we can move further.\n",
    "            if best_step is None or best_score <= current_score:\n",
    "                print(f'[{key}] No improvement')\n",
    "                # Restore current value.\n",
    "                setattr(estimator, key, current_value)\n",
    "                continue\n",
    "\n",
    "            # Move further.\n",
    "            early_stop = False\n",
    "            print(f'[{key}] Trying step: {best_step}. Got: {best_score}')\n",
    "            value = best_value\n",
    "            while True:\n",
    "                value += best_step\n",
    "                if not param.min <= value <= param.max:\n",
    "                    print(f'[{key}] Value outside bounds: {value}')\n",
    "                    break\n",
    "                # Evaluate model with the new value.\n",
    "                score = set_evaluate(key, value)\n",
    "                print(f'[{key}] Tried {value}: {score}')\n",
    "                if score <= best_score:\n",
    "                    # Could not improve further.\n",
    "                    break\n",
    "                # This value is better.\n",
    "                best_score, best_value = score, value\n",
    "                \n",
    "            # Set the best value.\n",
    "            current_score = best_score\n",
    "            setattr(estimator, key, best_value)\n",
    "            print(f'[{key}] New value: {best_value}. New score: {current_score}')\n",
    "        \n",
    "        if early_stop:\n",
    "            print()\n",
    "            print(f'Early stopping')\n",
    "            break\n",
    "            \n",
    "    print(f'Final score: {current_score}')\n",
    "\n",
    "    # Fit on the entire dataset if needed.\n",
    "    if refit:\n",
    "        estimator.fit(X, y)\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `smoke`, `alco` and `active`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_helper = train.drop(['smoke', 'alco', 'active', 'cardio'], axis=1).values\n",
    "\n",
    "y_smoke = train['smoke'].values\n",
    "y_alco = train['alco'].values\n",
    "y_active = train['active'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoke_estimator = xgboost.XGBClassifier(nthread=5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model\n",
      "Initial score: -0.23886296819062042\n",
      "\n",
      "Starting iteration 0. Current score: -0.23886296819062042\n",
      "[colsample_bytree] Current value: 0.99\n",
      "[colsample_bytree] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] Trying step: 0.01. Got: -0.23885996958642125\n",
      "[reg_alpha] Tried 0.03: -0.23886246593361982\n",
      "[reg_alpha] New value: 0.02. New score: -0.23885996958642125\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] Trying step: -0.01. Got: -0.2388594250855693\n",
      "[reg_lambda] Tried 0.98: -0.23886098068919287\n",
      "[reg_lambda] New value: 0.99. New score: -0.2388594250855693\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "[base_score] Current value: 0.51\n",
      "[base_score] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "\n",
      "Starting iteration 1. Current score: -0.2388594250855693\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] Trying step: 0.01. Got: -0.23885579819258088\n",
      "[gamma] Tried 0.02: -0.2388574881603401\n",
      "[gamma] New value: 0.01. New score: -0.23885579819258088\n",
      "[base_score] Current value: 0.51\n",
      "[base_score] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[colsample_bytree] Current value: 0.99\n",
      "[colsample_bytree] No improvement\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] No improvement\n",
      "[reg_alpha] Current value: 0.02\n",
      "[reg_alpha] No improvement\n",
      "[reg_lambda] Current value: 0.99\n",
      "[reg_lambda] No improvement\n",
      "\n",
      "Starting iteration 2. Current score: -0.23885579819258088\n",
      "[gamma] Current value: 0.01\n",
      "[gamma] No improvement\n",
      "[base_score] Current value: 0.51\n",
      "[base_score] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[colsample_bytree] Current value: 0.99\n",
      "[colsample_bytree] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[reg_alpha] Current value: 0.02\n",
      "[reg_alpha] No improvement\n",
      "[reg_lambda] Current value: 0.99\n",
      "[reg_lambda] No improvement\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "\n",
      "Early stopping\n",
      "Final score: -0.23885579819258088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.51, colsample_bylevel=1, colsample_bytree=0.99,\n",
       "       gamma=0.01, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=101, nthread=5,\n",
       "       objective='binary:logistic', reg_alpha=0.02, reg_lambda=0.99,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.97)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    smoke_estimator, X_helper, y_smoke, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "alco_estimator = xgboost.XGBClassifier(nthread=5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model\n",
      "Initial score: -0.19240139584600163\n",
      "\n",
      "Starting iteration 0. Current score: -0.19240139584600163\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[reg_alpha] Current value: 0\n",
      "[reg_alpha] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[subsample] Current value: 1\n",
      "[subsample] Trying step: -0.01. Got: -0.19237007084120925\n",
      "[subsample] Tried 0.98: -0.19234001700012576\n",
      "[subsample] Tried 0.97: -0.1923226390888372\n",
      "[subsample] Tried 0.96: -0.19232403579595364\n",
      "[subsample] New value: 0.97. New score: -0.1923226390888372\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] Trying step: -0.01. Got: -0.1923100056249212\n",
      "[reg_lambda] Tried 0.98: -0.19233244067110233\n",
      "[reg_lambda] New value: 0.99. New score: -0.1923100056249212\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] No improvement\n",
      "\n",
      "Starting iteration 1. Current score: -0.1923100056249212\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[reg_lambda] Current value: 0.99\n",
      "[reg_lambda] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "[reg_alpha] Current value: 0\n",
      "[reg_alpha] Trying step: 0.01. Got: -0.1923028469851887\n",
      "[reg_alpha] Tried 0.02: -0.19233693313324346\n",
      "[reg_alpha] New value: 0.01. New score: -0.1923028469851887\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] Trying step: 0.01. Got: -0.19228091096303873\n",
      "[base_score] Tried 0.52: -0.19232345190086525\n",
      "[base_score] New value: 0.51. New score: -0.19228091096303873\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "\n",
      "Starting iteration 2. Current score: -0.19228091096303873\n",
      "[reg_lambda] Current value: 0.99\n",
      "[reg_lambda] Trying step: 0.01. Got: -0.19227229089637268\n",
      "[reg_lambda] Value outside bounds: 1.01\n",
      "[reg_lambda] New value: 1.0. New score: -0.19227229089637268\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "[base_score] Current value: 0.51\n",
      "[base_score] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "\n",
      "Starting iteration 3. Current score: -0.19227229089637268\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[base_score] Current value: 0.51\n",
      "[base_score] No improvement\n",
      "[subsample] Current value: 0.97\n",
      "[subsample] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] No improvement\n",
      "[reg_lambda] Current value: 1.0\n",
      "[reg_lambda] No improvement\n",
      "\n",
      "Early stopping\n",
      "Final score: -0.19227229089637268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.51, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=5,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1.0,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.97)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    alco_estimator, X_helper, y_alco, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_estimator = xgboost.XGBClassifier(nthread=5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model\n",
      "Initial score: -0.49276407584835874\n",
      "\n",
      "Starting iteration 0. Current score: -0.49276407584835874\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] Trying step: 0.01. Got: -0.4926561522892731\n",
      "[learning_rate] Tried 0.12: -0.49268431598130913\n",
      "[learning_rate] New value: 0.11. New score: -0.4926561522892731\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] Trying step: 1. Got: -0.49264919387044215\n",
      "[n_estimators] Tried 102: -0.49265514594885296\n",
      "[n_estimators] New value: 101. New score: -0.49264919387044215\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "[reg_alpha] Current value: 0\n",
      "[reg_alpha] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] Trying step: 1. Got: -0.4925968661347799\n",
      "[max_depth] Tried 5: -0.4926068423801252\n",
      "[max_depth] New value: 4. New score: -0.4925968661347799\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "\n",
      "Starting iteration 1. Current score: -0.4925968661347799\n",
      "[reg_alpha] Current value: 0\n",
      "[reg_alpha] Trying step: 0.01. Got: -0.4924283564270994\n",
      "[reg_alpha] Tried 0.02: -0.49256340665713116\n",
      "[reg_alpha] New value: 0.01. New score: -0.4924283564270994\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[max_depth] Current value: 4\n",
      "[max_depth] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[learning_rate] Current value: 0.11\n",
      "[learning_rate] No improvement\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "\n",
      "Starting iteration 2. Current score: -0.4924283564270994\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[max_depth] Current value: 4\n",
      "[max_depth] No improvement\n",
      "[learning_rate] Current value: 0.11\n",
      "[learning_rate] No improvement\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[gamma] Current value: 0\n",
      "[gamma] No improvement\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "\n",
      "Early stopping\n",
      "Final score: -0.4924283564270994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.11, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=101, nthread=5,\n",
       "       objective='binary:logistic', reg_alpha=0.01, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    active_estimator, X_helper, y_active, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict `cardio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_importances(estimator):\n",
    "    for name, importance in sorted(zip(test, estimator.feature_importances_), key=operator.itemgetter(1), reverse=True):\n",
    "        print(f'{name}: {importance:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cardio_estimator = xgboost.XGBClassifier(nthread=5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating current model\n",
      "Initial score: -0.5394364373333194\n",
      "\n",
      "Starting iteration 0. Current score: -0.5394364373333194\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[learning_rate] Current value: 0.1\n",
      "[learning_rate] Trying step: 0.01. Got: -0.5393749453345829\n",
      "[learning_rate] Tried 0.12: -0.539346653216222\n",
      "[learning_rate] Tried 0.13: -0.5392163866601066\n",
      "[learning_rate] Tried 0.14: -0.539138600310165\n",
      "[learning_rate] Tried 0.15000000000000002: -0.5390872039404008\n",
      "[learning_rate] Tried 0.16000000000000003: -0.5390199100692072\n",
      "[learning_rate] Tried 0.17000000000000004: -0.5391587002114411\n",
      "[learning_rate] New value: 0.16000000000000003. New score: -0.5390199100692072\n",
      "[gamma] Current value: 0\n",
      "[gamma] Trying step: 0.01. Got: -0.5390128691927909\n",
      "[gamma] Tried 0.02: -0.5390128691927909\n",
      "[gamma] New value: 0.01. New score: -0.5390128691927909\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] No improvement\n",
      "[reg_alpha] Current value: 0\n",
      "[reg_alpha] Trying step: 0.01. Got: -0.5389575311896175\n",
      "[reg_alpha] Tried 0.02: -0.5390218693911357\n",
      "[reg_alpha] New value: 0.01. New score: -0.5389575311896175\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "\n",
      "Starting iteration 1. Current score: -0.5389575311896175\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "[learning_rate] Current value: 0.16000000000000003\n",
      "[learning_rate] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[n_estimators] Current value: 100\n",
      "[n_estimators] Trying step: 1. Got: -0.5389502415885686\n",
      "[n_estimators] Tried 102: -0.5389608283218686\n",
      "[n_estimators] New value: 101. New score: -0.5389502415885686\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[gamma] Current value: 0.01\n",
      "[gamma] No improvement\n",
      "[max_depth] Current value: 3\n",
      "[max_depth] Trying step: 1. Got: -0.5388430040005228\n",
      "[max_depth] Tried 5: -0.5394708244192603\n",
      "[max_depth] New value: 4. New score: -0.5388430040005228\n",
      "\n",
      "Starting iteration 2. Current score: -0.5388430040005228\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[max_depth] Current value: 4\n",
      "[max_depth] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "[n_estimators] Current value: 101\n",
      "[n_estimators] Trying step: 1. Got: -0.5388362715997392\n",
      "[n_estimators] Tried 103: -0.5388480220696453\n",
      "[n_estimators] New value: 102. New score: -0.5388362715997392\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[gamma] Current value: 0.01\n",
      "[gamma] Trying step: 0.01. Got: -0.5388306577281543\n",
      "[gamma] Tried 0.03: -0.5388293497221593\n",
      "[gamma] Tried 0.04: -0.5388279088845527\n",
      "[gamma] Tried 0.05: -0.5388322535754099\n",
      "[gamma] New value: 0.04. New score: -0.5388279088845527\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[learning_rate] Current value: 0.16000000000000003\n",
      "[learning_rate] No improvement\n",
      "\n",
      "Starting iteration 3. Current score: -0.5388279088845527\n",
      "[colsample_bytree] Current value: 1\n",
      "[colsample_bytree] No improvement\n",
      "[subsample] Current value: 1\n",
      "[subsample] No improvement\n",
      "[base_score] Current value: 0.5\n",
      "[base_score] No improvement\n",
      "[learning_rate] Current value: 0.16000000000000003\n",
      "[learning_rate] No improvement\n",
      "[scale_pos_weight] Current value: 1\n",
      "[scale_pos_weight] No improvement\n",
      "[gamma] Current value: 0.04\n",
      "[gamma] No improvement\n",
      "[max_depth] Current value: 4\n",
      "[max_depth] No improvement\n",
      "[n_estimators] Current value: 102\n",
      "[n_estimators] No improvement\n",
      "[reg_alpha] Current value: 0.01\n",
      "[reg_alpha] No improvement\n",
      "[reg_lambda] Current value: 1\n",
      "[reg_lambda] No improvement\n",
      "\n",
      "Early stopping\n",
      "Final score: -0.5388279088845527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.04, learning_rate=0.16000000000000003, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=102,\n",
       "       nthread=5, objective='binary:logistic', reg_alpha=0.01,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_estimator(\n",
    "    cardio_estimator, X, y, n_iter=100, scoring='neg_log_loss', cv=cv,\n",
    "    colsample_bytree=Param(0.5, 1.0, 0.01),\n",
    "    subsample=Param(0.5, 1.0, 0.01),\n",
    "    base_score=Param(0.0, 1.0, 0.01),\n",
    "    scale_pos_weight=Param(0.0, 1.0, 0.01),\n",
    "    reg_lambda=Param(0.0, 1.0, 0.01),\n",
    "    reg_alpha=Param(0.0, 1.0, 0.01),\n",
    "    gamma=Param(0.0, 1.0, 0.01),\n",
    "    learning_rate=Param(0.01, 1.0, 0.01),\n",
    "    max_depth=Param(1, 1000, 1),\n",
    "    n_estimators=Param(1, 1000, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.2669649\n",
      "bmi: 0.1707681\n",
      "ap_hi: 0.1431767\n",
      "height: 0.1066368\n",
      "weight: 0.0835198\n",
      "ap_lo: 0.0760626\n",
      "cholesterol: 0.0559284\n",
      "gluc: 0.0365399\n",
      "active: 0.0216257\n",
      "gender: 0.0141685\n",
      "smoke: 0.0134228\n",
      "alco: 0.0111857\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv')\n",
    "X_helper_test = test.drop(['smoke', 'alco', 'active'], axis=1).values\n",
    "\n",
    "test['smoke'].fillna(pandas.Series(smoke_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['alco'].fillna(pandas.Series(alco_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "test['active'].fillna(pandas.Series(active_estimator.predict_proba(X_helper_test)[:, 1]), inplace=True)\n",
    "\n",
    "numpy.savetxt(f'xgboost.txt', cardio_estimator.predict_proba(test.values)[:, 1], fmt='%f')\n",
    "\n",
    "print_importances(cardio_estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
